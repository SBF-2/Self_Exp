# train_PRM.py
import torch.nn.functional as F
import argparse
import logging
import os
import json
import torch
from tqdm import tqdm
import datetime
import csv
import colorama
from colorama import Fore, Back, Style
import sys

# DDP Imports
import torch.distributed as dist
from torch.nn.parallel import DistributedDataParallel as DDP
from torch.utils.data.distributed import DistributedSampler

# Import from other files
from env.AtariDataLoder import create_atari_dataloaders
from model.PRM import PRM, create_optimized_optimizer, create_lr_scheduler

logger = logging.getLogger(__name__)

def print_loss_info(loss_dict, global_step, epoch, batch_idx, lr=None, loss_type="TRAIN"):
    """
    ç”¨å½©è‰²æ‰“å°æŸå¤±ä¿¡æ¯
    """
    color = Fore.RED if loss_type == "TRAIN" else Fore.BLUE
    
    print(f"\n{color}{'='*60}")
    print(f"{color}ğŸ”¥ {loss_type} LOSS INFO - Step {global_step}")
    print(f"{color}{'='*60}")
    print(f"{Fore.YELLOW}Epoch: {epoch+1:3d} | Batch: {batch_idx+1:4d} | Step: {global_step:6d}")
    if lr is not None:
        print(f"{Fore.CYAN}Learning Rate: {lr:.2e}")
    
    print(f"{color}â”Œâ”€ LOSSES â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
    print(f"{color}â”‚ Total Loss:    {loss_dict['total_loss']:10.6f}              â”‚")
    print(f"{color}â”‚ Image Loss:    {loss_dict['loss_img']:10.6f}              â”‚")
    print(f"{color}â”‚ Done Loss:     {loss_dict['loss_done']:10.6f}              â”‚")
    print(f"{color}â”‚ Vector Loss:   {loss_dict['loss_vector']:10.6f}              â”‚")
    if 'cosine_similarity' in loss_dict:
        print(f"{color}â”‚ Cosine Sim:    {loss_dict['cosine_similarity']:10.6f}              â”‚")
    if 'done_accuracy' in loss_dict:
        print(f"{color}â”‚ Done Accuracy: {loss_dict['done_accuracy']:10.6f}              â”‚")
    if 'psnr' in loss_dict:
        print(f"{color}â”‚ PSNR:          {loss_dict['psnr']:10.2f} dB            â”‚")
    print(f"{color}â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
    print(f"{color}{'='*60}{Style.RESET_ALL}")


def setup_ddp():
    """Initializes the DDP process group."""
    dist.init_process_group(backend="nccl")
    rank = int(os.environ['RANK'])
    world_size = int(os.environ['WORLD_SIZE'])
    local_rank = int(os.environ['LOCAL_RANK'])
    torch.cuda.set_device(local_rank)
    return rank, world_size


def cleanup_ddp():
    """Cleans up the DDP process group."""
    dist.destroy_process_group()


def add_all_training_args(parser: argparse.ArgumentParser):
    """æ·»åŠ æ‰€æœ‰è®­ç»ƒç›¸å…³çš„å‚æ•°"""
    
    # === æ•°æ®è·¯å¾„å’ŒåŠ è½½é…ç½® ===
    data_group = parser.add_argument_group('Data Loading Configuration')
    data_group.add_argument('--data-dir', type=str, default='./Data/replay_data',
                           help='Directory containing PKL files')
    data_group.add_argument('--num-workers', type=int, default=4,
                           help='Number of data loading worker processes')
    
    # === æ•°æ®é¢„å¤„ç†é…ç½® ===
    preprocess_group = parser.add_argument_group('Data Preprocessing Configuration')
    preprocess_group.add_argument('--img-height', type=int, default=210,
                                 help='Target image height')
    preprocess_group.add_argument('--img-width', type=int, default=160,
                                 help='Target image width')
    
    # === åºåˆ—å’Œæ‰¹æ¬¡é…ç½® ===
    sequence_group = parser.add_argument_group('Sequence and Batch Configuration')
    sequence_group.add_argument('--sequence-length', type=int, default=32,
                               help='Length of each training sequence (model will see sequence_length+1 frames)')
    sequence_group.add_argument('--batch-size', type=int, default=8,
                               help='Number of sequences per batch')
    sequence_group.add_argument('--overlap-steps', type=int, default=16,
                               help='Number of steps to move forward when creating overlapping sequences')
    
    # === æ•°æ®é›†åˆ’åˆ†é…ç½® ===
    split_group = parser.add_argument_group('Dataset Split Configuration')
    split_group.add_argument('--train-split', type=float, default=0.8,
                            help='Proportion of episodes for training')
    split_group.add_argument('--val-split', type=float, default=0.1,
                            help='Proportion of episodes for validation')
    
    # === è®­ç»ƒé…ç½® ===
    train_group = parser.add_argument_group('Training Configuration')
    train_group.add_argument('--epochs', type=int, default=50, 
                            help='Number of training epochs')
    train_group.add_argument('--output-dir', type=str, default='./Output', 
                            help='Base directory to save all training outputs')
    train_group.add_argument('--run-name', type=str, default='episode_100', 
                            help='A specific name for this training run')
    train_group.add_argument('--log-interval', type=int, default=50, 
                            help='How often (in batches) to log to CSV')

    # === PRM æ¨¡å‹é…ç½® ===
    model_group = parser.add_argument_group('PRM Model Configuration')
    model_group.add_argument('--latent-dim', type=int, default=256, 
                            help='Dimension of the latent space')
    model_group.add_argument('--base-channels', type=int, default=64, 
                            help='Base number of channels for convolutional layers')
    model_group.add_argument('--transformer-layers', type=int, default=3, 
                            help='Number of layers in the Transformer predictor')
    model_group.add_argument('--num-attention-heads', type=int, default=8, 
                            help='Number of attention heads in the Transformer')
    model_group.add_argument('--loss-weights', type=float, nargs=3, default=[1.0, 1.0, 1.0], 
                            help='Weights for [image, done, vector] losses')
    model_group.add_argument('--no-skip-connections', action='store_true', 
                            help='Disable skip connections in the ImageDecoder')
    
    # === ä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨é…ç½® ===
    optim_group = parser.add_argument_group('Optimizer and Scheduler Configuration')
    optim_group.add_argument('--lr', type=float, default=1e-4, 
                            help='Base learning rate')
    optim_group.add_argument('--weight-decay', type=float, default=1e-2, 
                            help='Weight decay for the AdamW optimizer')
    optim_group.add_argument('--warmup-steps', type=int, default=1000, 
                            help='Number of warmup steps for the learning rate scheduler')
    optim_group.add_argument('--grad-clip-norm', type=float, default=1.0, 
                            help='Maximum norm for gradient clipping')
    
    # === è°ƒè¯•å’Œæ—¥å¿—é…ç½® ===
    debug_group = parser.add_argument_group('Debug and Logging Configuration')
    debug_group.add_argument('--log-level', type=str, default='INFO',
                            choices=['DEBUG', 'INFO', 'WARNING', 'ERROR'],
                            help='Logging level')
    debug_group.add_argument('--max-episodes', type=int, default=None,
                            help='Maximum number of episodes to use (for debugging)')

# def train_epoch(model, dataloader, optimizer, scheduler, device, args, epoch, csv_writer, csv_file, rank):
#     """
#     ä¿®æ”¹åçš„è®­ç»ƒå‡½æ•°ï¼šæ·»åŠ æ¯64ä¸ªbatchçš„è¯„ä¼°å’Œå½©è‰²æ—¥å¿—
#     """
#     model.train()
#     progress_bar = tqdm(dataloader, desc=f"Training Epoch {epoch+1}", leave=False, disable=(rank != 0))

#     batch_count = 0
#     last_batch_data = None  # ä¿å­˜æœ€åä¸€ä¸ªbatchç”¨äºè¯„ä¼°
    
#     for batch_idx, batch in enumerate(progress_bar):
#         global_step = epoch * len(dataloader) + batch_idx
#         batch_count += 1
        
#         optimizer.zero_grad()
#         obs = batch['observations'].to(device, non_blocking=True)
#         actions = batch['actions'].to(device, non_blocking=True)
#         done = batch['done'].to(device, non_blocking=True)
        
#         B, T_plus_1, C, H, W = obs.shape
#         T = T_plus_1 - 1
        
#         input_images = obs[:, :-1, ...].reshape(B*T, C, H, W)
#         input_actions = actions[:, :-1].reshape(B*T)
#         target_images = obs[:, 1:, ...].reshape(B*T, C, H, W)
#         target_done = done[:, 1:].reshape(B*T)

#         _, predicted_features, predicted_images, predicted_done = model(input_images, input_actions)
        
#         with torch.no_grad():
#             target_features, _ = model.module.encoder(target_images)
            
#         loss, loss_dict = model.module.compute_loss(
#             predicted_images, target_images, predicted_done,
#             target_done, predicted_features, target_features
#         )
        
#         loss.backward()
#         torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=args.grad_clip_norm)
#         optimizer.step()
#         scheduler.step()

#         # ä¿å­˜å½“å‰batchæ•°æ®ç”¨äºè¯„ä¼°
#         last_batch_data = batch

#         if rank == 0:
#             current_lr = optimizer.param_groups[0]['lr']
            
#             # æ›´æ–°è¿›åº¦æ¡
#             progress_bar.set_postfix({
#                 'loss': f"{loss.item():.4f}",
#                 'img': f"{loss_dict['loss_img']:.4f}",
#                 'done': f"{loss_dict['loss_done']:.4f}",
#                 'vec': f"{loss_dict['loss_vector']:.4f}",
#                 'lr': f"{current_lr:.2e}"
#             })
            
#             # ğŸ”¥ æ¯64ä¸ªbatchè¿›è¡Œè¯„ä¼°å’Œæ‰“å°
#             if batch_count % 64 == 0:
#                 # è®­ç»ƒæŸå¤±ä¿¡æ¯ï¼ˆçº¢è‰²ï¼‰
#                 print_loss_info(loss_dict, global_step + 1, epoch, batch_idx, current_lr, "TRAIN")
                
#                 # åœ¨å½“å‰batchä¸Šè¿›è¡Œè¯„ä¼°ï¼ˆè“è‰²ï¼‰
#                 eval_loss_dict = evaluate_on_current_batch(model, last_batch_data, device)
#                 print_loss_info(eval_loss_dict, global_step + 1, epoch, batch_idx, current_lr, "EVAL")
                
#                 # å†™å…¥CSV - è®­ç»ƒå’Œè¯„ä¼°æŸå¤±éƒ½è®°å½•
#                 if csv_writer is not None and csv_file is not None:
#                     try:
#                         # è®­ç»ƒæŸå¤±è¡Œ
#                         train_log_data = [
#                             global_step + 1,
#                             "train",
#                             loss_dict['total_loss'],
#                             loss_dict['loss_img'],
#                             loss_dict['loss_done'],
#                             loss_dict['loss_vector'],
#                             loss_dict.get('cosine_similarity', 0.0),
#                             0.0,  # done_accuracy (è®­ç»ƒæ—¶ä¸è®¡ç®—)
#                             0.0,  # psnr (è®­ç»ƒæ—¶ä¸è®¡ç®—)
#                             current_lr
#                         ]
#                         csv_writer.writerow(train_log_data)
                        
#                         # è¯„ä¼°æŸå¤±è¡Œ
#                         eval_log_data = [
#                             global_step + 1,
#                             "eval",
#                             eval_loss_dict['total_loss'],
#                             eval_loss_dict['loss_img'],
#                             eval_loss_dict['loss_done'],
#                             eval_loss_dict['loss_vector'],
#                             eval_loss_dict.get('cosine_similarity', 0.0),
#                             eval_loss_dict.get('done_accuracy', 0.0),
#                             eval_loss_dict.get('psnr', 0.0),
#                             current_lr
#                         ]
#                         csv_writer.writerow(eval_log_data)
                        
#                         # å¼ºåˆ¶åˆ·æ–°æ–‡ä»¶
#                         csv_file.flush()
                        
#                     except Exception as e:
#                         print(f"{Fore.RED}CSVå†™å…¥é”™è¯¯: {e}{Style.RESET_ALL}")
            
#             # å¸¸è§„æ—¥å¿—è®°å½•ï¼ˆæ¯ä¸ªbatchï¼‰
#             elif (batch_idx + 1) % args.log_interval == 0 and csv_writer is not None and csv_file is not None:
#                 try:
#                     regular_log_data = [
#                         global_step + 1,
#                         "train",
#                         loss_dict['total_loss'],
#                         loss_dict['loss_img'],
#                         loss_dict['loss_done'],
#                         loss_dict['loss_vector'],
#                         loss_dict.get('cosine_similarity', 0.0),
#                         0.0,  # done_accuracy
#                         0.0,  # psnr
#                         current_lr
#                     ]
#                     csv_writer.writerow(regular_log_data)
#                     csv_file.flush()
#                 except Exception as e:
#                     print(f"{Fore.RED}CSVå†™å…¥é”™è¯¯: {e}{Style.RESET_ALL}")


# åŠ¨æ€è°ƒæ•´è¯„ä¼°é¢‘ç‡ï¼šæ ¹æ®æ€»batchæ•°è‡ªåŠ¨è°ƒæ•´
# ç¡®ä¿æ¯ä¸ªepochéƒ½æœ‰è®°å½•ï¼šåœ¨æœ€åä¸€ä¸ªbatchå¼ºåˆ¶è®°å½•
# æ›´æ™ºèƒ½çš„æ—¥å¿—é—´éš”ï¼šè‡ªé€‚åº”è°ƒæ•´åˆ°åˆç†çš„å€¼
def train_epoch(model, dataloader, optimizer, scheduler, device, args, epoch, csv_writer, csv_file, rank):
    """
    ä¿®æ”¹åçš„è®­ç»ƒå‡½æ•°ï¼šæ·»åŠ æ¯64ä¸ªbatchçš„è¯„ä¼°å’Œå½©è‰²æ—¥å¿—
    """
    model.train()
    progress_bar = tqdm(dataloader, desc=f"Training Epoch {epoch+1}", leave=False, disable=(rank != 0))

    batch_count = 0
    last_batch_data = None  # ä¿å­˜æœ€åä¸€ä¸ªbatchç”¨äºè¯„ä¼°
    
    #  ä¿®å¤ï¼šåŠ¨æ€è°ƒæ•´è¯„ä¼°é¢‘ç‡
    total_batches = len(dataloader)
    eval_interval = min(64, max(10, total_batches // 4))  # è¯„ä¼°é—´éš”ï¼šæœ€å°10ï¼Œæœ€å¤§64ï¼Œæˆ–æ€»batchæ•°çš„1/4
    log_interval = min(args.log_interval, max(5, total_batches // 8))  # æ—¥å¿—é—´éš”ï¼šè°ƒæ•´ä¸ºæ›´åˆç†çš„å€¼
    
    if rank == 0:
        print(f"{Fore.CYAN}ğŸ“Š Training with {total_batches} batches per epoch")
        print(f"{Fore.CYAN}ğŸ“Š Evaluation every {eval_interval} batches")
        print(f"{Fore.CYAN}ğŸ“Š Regular logging every {log_interval} batches{Style.RESET_ALL}")
    
    for batch_idx, batch in enumerate(progress_bar):
        global_step = epoch * len(dataloader) + batch_idx
        batch_count += 1
        
        optimizer.zero_grad()
        obs = batch['observations'].to(device, non_blocking=True)
        actions = batch['actions'].to(device, non_blocking=True)
        done = batch['done'].to(device, non_blocking=True)
        
        B, T_plus_1, C, H, W = obs.shape
        T = T_plus_1 - 1
        
        input_images = obs[:, :-1, ...].reshape(B*T, C, H, W)
        input_actions = actions[:, :-1].reshape(B*T)
        target_images = obs[:, 1:, ...].reshape(B*T, C, H, W)
        target_done = done[:, 1:].reshape(B*T)

        _, predicted_features, predicted_images, predicted_done = model(input_images, input_actions)
        
        with torch.no_grad():
            target_features, _ = model.module.encoder(target_images)
            
        loss, loss_dict = model.module.compute_loss(
            predicted_images, target_images, predicted_done,
            target_done, predicted_features, target_features
        )
        
        loss.backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=args.grad_clip_norm)
        optimizer.step()
        scheduler.step()

        # ä¿å­˜å½“å‰batchæ•°æ®ç”¨äºè¯„ä¼°
        last_batch_data = batch

        if rank == 0:
            current_lr = optimizer.param_groups[0]['lr']
            
            # æ›´æ–°è¿›åº¦æ¡
            progress_bar.set_postfix({
                'loss': f"{loss.item():.4f}",
                'img': f"{loss_dict['loss_img']:.4f}",
                'done': f"{loss_dict['loss_done']:.4f}",
                'vec': f"{loss_dict['loss_vector']:.4f}",
                'lr': f"{current_lr:.2e}"
            })
            
            # ğŸ”¥ ä¿®å¤ï¼šä½¿ç”¨åŠ¨æ€è°ƒæ•´çš„è¯„ä¼°é¢‘ç‡
            if batch_count % eval_interval == 0:
                # è®­ç»ƒæŸå¤±ä¿¡æ¯ï¼ˆçº¢è‰²ï¼‰
                print_loss_info(loss_dict, global_step + 1, epoch, batch_idx, current_lr, "TRAIN")
                
                # åœ¨å½“å‰batchä¸Šè¿›è¡Œè¯„ä¼°ï¼ˆè“è‰²ï¼‰
                eval_loss_dict = evaluate_on_current_batch(model, last_batch_data, device)
                print_loss_info(eval_loss_dict, global_step + 1, epoch, batch_idx, current_lr, "EVAL")
                
                # å†™å…¥CSV - è®­ç»ƒå’Œè¯„ä¼°æŸå¤±éƒ½è®°å½•
                if csv_writer is not None and csv_file is not None:
                    try:
                        # è®­ç»ƒæŸå¤±è¡Œ
                        train_log_data = [
                            global_step + 1,
                            "train",
                            loss_dict['total_loss'],
                            loss_dict['loss_img'],
                            loss_dict['loss_done'],
                            loss_dict['loss_vector'],
                            loss_dict.get('cosine_similarity', 0.0),
                            0.0,  # done_accuracy (è®­ç»ƒæ—¶ä¸è®¡ç®—)
                            0.0,  # psnr (è®­ç»ƒæ—¶ä¸è®¡ç®—)
                            current_lr
                        ]
                        csv_writer.writerow(train_log_data)
                        
                        # è¯„ä¼°æŸå¤±è¡Œ
                        eval_log_data = [
                            global_step + 1,
                            "eval",
                            eval_loss_dict['total_loss'],
                            eval_loss_dict['loss_img'],
                            eval_loss_dict['loss_done'],
                            eval_loss_dict['loss_vector'],
                            eval_loss_dict.get('cosine_similarity', 0.0),
                            eval_loss_dict.get('done_accuracy', 0.0),
                            eval_loss_dict.get('psnr', 0.0),
                            current_lr
                        ]
                        csv_writer.writerow(eval_log_data)
                        
                        # å¼ºåˆ¶åˆ·æ–°æ–‡ä»¶
                        csv_file.flush()
                        
                    except Exception as e:
                        print(f"{Fore.RED}CSVå†™å…¥é”™è¯¯: {e}{Style.RESET_ALL}")
            
            # ğŸ”¥ ä¿®å¤ï¼šä½¿ç”¨åŠ¨æ€è°ƒæ•´çš„æ—¥å¿—é¢‘ç‡
            elif (batch_idx + 1) % log_interval == 0 and csv_writer is not None and csv_file is not None:
                try:
                    regular_log_data = [
                        global_step + 1,
                        "train",
                        loss_dict['total_loss'],
                        loss_dict['loss_img'],
                        loss_dict['loss_done'],
                        loss_dict['loss_vector'],
                        loss_dict.get('cosine_similarity', 0.0),
                        0.0,  # done_accuracy
                        0.0,  # psnr
                        current_lr
                    ]
                    csv_writer.writerow(regular_log_data)
                    csv_file.flush()
                except Exception as e:
                    print(f"{Fore.RED}CSVå†™å…¥é”™è¯¯: {e}{Style.RESET_ALL}")
            
            # ğŸ”¥ æ–°å¢ï¼šç¡®ä¿æ¯ä¸ªepochè‡³å°‘è®°å½•ä¸€æ¬¡ï¼ˆæœ€åä¸€ä¸ªbatchï¼‰
            elif batch_idx == len(dataloader) - 1 and csv_writer is not None and csv_file is not None:
                try:
                    final_log_data = [
                        global_step + 1,
                        "train_final",
                        loss_dict['total_loss'],
                        loss_dict['loss_img'],
                        loss_dict['loss_done'],
                        loss_dict['loss_vector'],
                        loss_dict.get('cosine_similarity', 0.0),
                        0.0,  # done_accuracy
                        0.0,  # psnr
                        current_lr
                    ]
                    csv_writer.writerow(final_log_data)
                    csv_file.flush()
                    print(f"{Fore.GREEN}ğŸ“ Epoch {epoch+1} final batch logged{Style.RESET_ALL}")
                except Exception as e:
                    print(f"{Fore.RED}CSVå†™å…¥é”™è¯¯: {e}{Style.RESET_ALL}")

def evaluate_on_current_batch(model, batch, device):
    """
    åœ¨å½“å‰batchä¸Šè¿›è¡Œè¯„ä¼°ï¼ˆä¸éœ€è¦é¢å¤–çš„éªŒè¯æ•°æ®ï¼‰
    """
    model.eval()
    
    with torch.no_grad():
        obs = batch['observations'].to(device, non_blocking=True)
        actions = batch['actions'].to(device, non_blocking=True)
        done = batch['done'].to(device, non_blocking=True)
        
        B, T_plus_1, C, H, W = obs.shape
        T = T_plus_1 - 1
        
        input_images = obs[:, :-1, ...].reshape(B*T, C, H, W)
        input_actions = actions[:, :-1].reshape(B*T)
        target_images = obs[:, 1:, ...].reshape(B*T, C, H, W)
        target_done = done[:, 1:].reshape(B*T)

        _, predicted_features, predicted_images, predicted_done = model(input_images, input_actions)
        
        target_features, _ = model.module.encoder(target_images)
            
        loss, loss_dict = model.module.compute_loss(
            predicted_images, target_images, predicted_done,
            target_done, predicted_features, target_features
        )
        
        # è®¡ç®—é¢å¤–çš„è¯„ä¼°æŒ‡æ ‡
        # Doneé¢„æµ‹å‡†ç¡®ç‡
        done_pred_binary = (predicted_done > 0.5).float()
        done_accuracy = (done_pred_binary.view(-1) == target_done.float()).float().mean()
        
        # å›¾åƒé‡å»ºPSNR
        mse_img = F.mse_loss(predicted_images, target_images, reduction='mean')
        psnr = 20 * torch.log10(1.0 / torch.sqrt(mse_img + 1e-8))
        
        # æ·»åŠ é¢å¤–è¯„ä¼°æŒ‡æ ‡åˆ°loss_dict
        loss_dict.update({
            'done_accuracy': done_accuracy.item(),
            'psnr': psnr.item(),
            'mse_img': mse_img.item()
        })
    
    model.train()  # åˆ‡å›è®­ç»ƒæ¨¡å¼
    return loss_dict

def validate_epoch(model, dataloader, device):
    """æ‰§è¡Œä¸€ä¸ªéªŒè¯epoch"""
    model.eval()
    total_val_loss = 0
    all_loss_dicts = []
    
    with torch.no_grad():
        progress_bar = tqdm(dataloader, desc="Validating", leave=False)
        for batch in progress_bar:
            obs = batch['observations'].to(device)
            actions = batch['actions'].to(device)
            done = batch['done'].to(device)

            B, T_plus_1, C, H, W = obs.shape
            T = T_plus_1 - 1

            input_images = obs[:, :-1, ...].reshape(B*T, C, H, W)
            input_actions = actions[:, :-1].reshape(B*T)
            target_images = obs[:, 1:, ...].reshape(B*T, C, H, W)
            target_done = done[:, 1:].reshape(B*T)

            _, predicted_features, predicted_images, predicted_done = model(input_images, input_actions)
            target_features, _ = model.encoder(target_images)
            
            _, loss_dict = model.compute_loss(
                predicted_images, target_images, predicted_done,
                target_done, predicted_features, target_features
            )
            
            # è®¡ç®—é¢å¤–çš„éªŒè¯æŒ‡æ ‡
            done_pred_binary = (predicted_done > 0.5).float()
            done_accuracy = (done_pred_binary.view(-1) == target_done.float()).float().mean()
            mse_img = torch.nn.functional.mse_loss(predicted_images, target_images)
            psnr = 20 * torch.log10(1.0 / torch.sqrt(mse_img + 1e-8))

            loss_dict['done_accuracy'] = done_accuracy.item()
            loss_dict['psnr'] = psnr.item()
            all_loss_dicts.append(loss_dict)
            total_val_loss += loss_dict['total_loss']
    
    # è®¡ç®—æ‰€æœ‰éªŒè¯æ‰¹æ¬¡çš„å¹³å‡æŒ‡æ ‡
    avg_metrics = {k: sum(d[k] for d in all_loss_dicts) / len(all_loss_dicts) for k in all_loss_dicts[0]}
    return total_val_loss / len(dataloader), avg_metrics

def main():
    """
    ä¿®æ”¹åçš„ä¸»å‡½æ•°
    """
    parser = argparse.ArgumentParser(description="Train a PRM with DDP and unified logging.")
    add_all_training_args(parser)
    args = parser.parse_args()

    logging.getLogger().setLevel(getattr(logging, args.log_level))

    rank, world_size = setup_ddp()
    device = torch.device(f"cuda:{rank}")

    csv_writer, csv_file, run_path = None, None, None

    if rank == 0:
        run_path = os.path.join(args.output_dir, args.run_name)
        os.makedirs(run_path, exist_ok=True)
        
        log_file_path = os.path.join(run_path, 'training.log')
        logging.basicConfig(
            level=getattr(logging, args.log_level), 
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[logging.FileHandler(log_file_path), logging.StreamHandler()]
        )
        
        # ğŸ”¥ ä¿®å¤CSVæ–‡ä»¶åˆ›å»º - æ·»åŠ æ›´å¤šåˆ—
        csv_file_path = os.path.join(run_path, 'loss_log.csv')
        csv_file = open(csv_file_path, 'w', newline='', encoding='utf-8')
        csv_writer = csv.writer(csv_file)
        
        # åŒ…å«è®­ç»ƒå’Œè¯„ä¼°ä¿¡æ¯çš„CSVè¡¨å¤´
        csv_writer.writerow([
            'global_step', 'mode', 'total_loss', 'loss_img', 'loss_done', 
            'loss_vector', 'cosine_similarity', 'done_accuracy', 'psnr', 'learning_rate'
        ])
        csv_file.flush()  # ç«‹å³å†™å…¥è¡¨å¤´

        print(f"{Fore.GREEN}{'='*60}")
        print(f"{Fore.GREEN}ğŸš€ Starting DDP Training with Evaluation")
        print(f"{Fore.GREEN}{'='*60}")
        print(f"{Fore.CYAN}Run name: {args.run_name}")
        print(f"{Fore.CYAN}Output dir: {run_path}")
        print(f"{Fore.CYAN}GPUs: {world_size}")
        print(f"{Fore.CYAN}Batch size per GPU: {args.batch_size}")
        print(f"{Fore.CYAN}Sequence length: {args.sequence_length}")
        print(f"{Fore.CYAN}Effective batch size: {args.batch_size * args.sequence_length * world_size}")
        print(f"{Fore.YELLOW}Evaluation: Every 64 batches on current batch")
        print(f"{Fore.GREEN}{'='*60}{Style.RESET_ALL}")
        
        with open(os.path.join(run_path, 'config.json'), 'w') as f:
            json.dump(vars(args), f, indent=4)

    # ä½¿ç”¨åŸæœ‰çš„æ•°æ®åŠ è½½å™¨ï¼ˆä¸ä¿®æ”¹ï¼‰
    train_loader, val_loader = create_atari_dataloaders(args)
    
    if train_loader is None:
        logger.error("Failed to create train loader. Exiting.")
        cleanup_ddp()
        return
    
    # ä¸º DDP åˆ›å»ºåˆ†å¸ƒå¼é‡‡æ ·å™¨
    train_dataset = train_loader.dataset
    train_sampler = DistributedSampler(train_dataset, num_replicas=world_size, rank=rank, shuffle=True)
    train_loader = torch.utils.data.DataLoader(
        train_dataset, 
        batch_size=args.batch_size, 
        shuffle=False,
        num_workers=args.num_workers, 
        pin_memory=True, 
        sampler=train_sampler, 
        drop_last=True
    )
    
    if rank == 0:
        if val_loader is not None:
            print(f"{Fore.GREEN}âœ… Created dataloaders - Train: {len(train_loader)}, Val: {len(val_loader)}{Style.RESET_ALL}")
            print(f"{Fore.YELLOW}ğŸ“ Note: Using current batch evaluation instead of separate validation{Style.RESET_ALL}")
        else:
            print(f"{Fore.YELLOW}âœ… Created dataloaders - Train: {len(train_loader)} (no validation){Style.RESET_ALL}")

    # æ¨¡å‹ã€ä¼˜åŒ–å™¨ã€è°ƒåº¦å™¨ï¼ˆä¿æŒä¸å˜ï¼‰
    model = PRM(
        use_skip_connections=(not args.no_skip_connections), 
        latent_dim=args.latent_dim,
        base_channels=args.base_channels,
        transformer_layers=args.transformer_layers,
        num_attention_heads=args.num_attention_heads,
        loss_weights=args.loss_weights
    ).to(device)
    
    model = DDP(model, device_ids=[rank], find_unused_parameters=False)
    optimizer = create_optimized_optimizer(model, base_lr=args.lr, weight_decay=args.weight_decay)
    max_steps = args.epochs * len(train_loader)
    scheduler = create_lr_scheduler(optimizer, warmup_steps=args.warmup_steps, max_steps=max_steps)

    # è®­ç»ƒå¾ªç¯
    best_val_loss = float('inf')
    for epoch in range(args.epochs):
        train_sampler.set_epoch(epoch)
        
        if rank == 0:
            print(f"\n{Fore.MAGENTA}{'='*60}")
            print(f"{Fore.MAGENTA}ğŸ¯ EPOCH {epoch+1}/{args.epochs}")
            print(f"{Fore.MAGENTA}{'='*60}{Style.RESET_ALL}")
        
        # ğŸ”¥ ä½¿ç”¨ä¿®æ”¹åçš„è®­ç»ƒå‡½æ•°
        train_epoch(model, train_loader, optimizer, scheduler, device, args, epoch, csv_writer, csv_file, rank)
        
        if rank == 0:
            # ç”±äºæˆ‘ä»¬æ¯64ä¸ªbatchè¿›è¡Œè¯„ä¼°ï¼Œè¿™é‡Œåªä¿å­˜æ¨¡å‹
            checkpoint_path = os.path.join(run_path, f'model_epoch_{epoch+1}.pth')
            torch.save(model.module.state_dict(), checkpoint_path)
            print(f"{Fore.GREEN}ğŸ’¾ Epoch {epoch+1} model saved!{Style.RESET_ALL}")

    if rank == 0:
        final_checkpoint_path = os.path.join(run_path, 'final_model.pth')
        torch.save(model.module.state_dict(), final_checkpoint_path)
        print(f"\n{Fore.GREEN}{'='*60}")
        print(f"{Fore.GREEN}ğŸ‰ TRAINING COMPLETED!")
        print(f"{Fore.GREEN}{'='*60}")
        print(f"{Fore.GREEN}Final model saved: {final_checkpoint_path}")
        print(f"{Fore.GREEN}Loss log saved: {csv_file.name}")
        print(f"{Fore.GREEN}{'='*60}{Style.RESET_ALL}")
        
        if csv_file:
            csv_file.close()
    
    cleanup_ddp()


if __name__ == '__main__':
    main()
