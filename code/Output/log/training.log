Step: 100/20000, Average Loss: 11125.030684
Step: 200/20000, Average Loss: 10685.273965
Step: 300/20000, Average Loss: 10555.136572
Step: 400/20000, Average Loss: 10259.527646
Step: 500/20000, Average Loss: 9870.176592
Step: 600/20000, Average Loss: 9793.687100
Step: 700/20000, Average Loss: 9706.948633
Step: 800/20000, Average Loss: 9787.414434
Step: 900/20000, Average Loss: 9884.358506
Step: 1000/20000, Average Loss: 9786.782354
Saved model checkpoint to trained_models_attention/ppm_attention_step_1000.pth
Step: 1100/20000, Average Loss: 9554.615820
Step: 1200/20000, Average Loss: 9378.767764
Step: 1300/20000, Average Loss: 9135.765977
Step: 1400/20000, Average Loss: 8945.358232
Step: 1500/20000, Average Loss: 8806.145547
Step: 1600/20000, Average Loss: 8554.793408
Step: 1700/20000, Average Loss: 8515.186699
Step: 1800/20000, Average Loss: 8397.410439
Step: 1900/20000, Average Loss: 8163.892144
Step: 2000/20000, Average Loss: 7893.816040
Saved model checkpoint to trained_models_attention/ppm_attention_step_2000.pth
Step: 2100/20000, Average Loss: 7639.115928
Step: 2200/20000, Average Loss: 7321.161216
Step: 2300/20000, Average Loss: 7052.632817
Step: 2400/20000, Average Loss: 6853.202954
Step: 2500/20000, Average Loss: 6676.686479
Step: 2600/20000, Average Loss: 6432.225220
Step: 2700/20000, Average Loss: 6298.847183
Step: 2800/20000, Average Loss: 6092.759224
Step: 2900/20000, Average Loss: 5786.045107
Step: 3000/20000, Average Loss: 5593.757744
Saved model checkpoint to trained_models_attention/ppm_attention_step_3000.pth
Step: 3100/20000, Average Loss: 5418.302036
Step: 3200/20000, Average Loss: 5224.361265
Step: 3300/20000, Average Loss: 4962.400000
Step: 3400/20000, Average Loss: 4784.363691
Step: 3500/20000, Average Loss: 4573.708931
Step: 3600/20000, Average Loss: 4353.439595
Step: 3700/20000, Average Loss: 4206.520322
Step: 3800/20000, Average Loss: 3972.563853
Step: 3900/20000, Average Loss: 3859.431370
Step: 4000/20000, Average Loss: 3728.331926
Saved model checkpoint to trained_models_attention/ppm_attention_step_4000.pth
Step: 4100/20000, Average Loss: 3607.391863
Step: 4200/20000, Average Loss: 3470.390681
Step: 4300/20000, Average Loss: 3327.942795
Step: 4400/20000, Average Loss: 3138.605405
Step: 4500/20000, Average Loss: 3000.475151
Step: 4600/20000, Average Loss: 2848.217893
Step: 4700/20000, Average Loss: 2664.787920
Step: 4800/20000, Average Loss: 2555.597737
Step: 4900/20000, Average Loss: 2440.304629
Step: 5000/20000, Average Loss: 2308.914490
Saved model checkpoint to trained_models_attention/ppm_attention_step_5000.pth
Step: 5100/20000, Average Loss: 2219.198411
Step: 5200/20000, Average Loss: 2099.004700
Step: 5300/20000, Average Loss: 2019.934495
Step: 5400/20000, Average Loss: 1886.576473
Step: 5500/20000, Average Loss: 1800.827311
Step: 5600/20000, Average Loss: 1688.501838
Step: 5700/20000, Average Loss: 1602.080885
Step: 5800/20000, Average Loss: 1536.732495
Step: 5900/20000, Average Loss: 1466.595808
Step: 6000/20000, Average Loss: 1398.625520
Saved model checkpoint to trained_models_attention/ppm_attention_step_6000.pth
Step: 6100/20000, Average Loss: 1290.475558
Step: 6200/20000, Average Loss: 1205.523473
Step: 6300/20000, Average Loss: 1167.248898
Step: 6400/20000, Average Loss: 1100.907528
Step: 6500/20000, Average Loss: 1041.080732
Step: 6600/20000, Average Loss: 976.101810
Step: 6700/20000, Average Loss: 906.996408
Step: 6800/20000, Average Loss: 843.432860
Step: 6900/20000, Average Loss: 801.112829
Step: 7000/20000, Average Loss: 735.306155
Saved model checkpoint to trained_models_attention/ppm_attention_step_7000.pth
Step: 7100/20000, Average Loss: 687.555031
Step: 7200/20000, Average Loss: 638.755823
Step: 7300/20000, Average Loss: 593.919539
Step: 7400/20000, Average Loss: 533.330594
Step: 7500/20000, Average Loss: 497.072063
Step: 7600/20000, Average Loss: 450.218728
Step: 7700/20000, Average Loss: 425.947260
Step: 7800/20000, Average Loss: 388.453129
Step: 7900/20000, Average Loss: 351.757569
Step: 8000/20000, Average Loss: 316.960247
Saved model checkpoint to trained_models_attention/ppm_attention_step_8000.pth
Step: 8100/20000, Average Loss: 300.364658
Step: 8200/20000, Average Loss: 267.685933
Step: 8300/20000, Average Loss: 241.628848
Step: 8400/20000, Average Loss: 220.979859
Step: 8500/20000, Average Loss: 204.028081
Step: 8600/20000, Average Loss: 183.591374
Step: 8700/20000, Average Loss: 168.818825
Step: 8800/20000, Average Loss: 155.581728
Step: 8900/20000, Average Loss: 137.618758
Step: 9000/20000, Average Loss: 129.402881
Saved model checkpoint to trained_models_attention/ppm_attention_step_9000.pth
Step: 9100/20000, Average Loss: 114.092088
Step: 9200/20000, Average Loss: 105.025387
Step: 9300/20000, Average Loss: 105.067101
Step: 9400/20000, Average Loss: 94.507062
Step: 9500/20000, Average Loss: 88.281124
Step: 9600/20000, Average Loss: 87.211301
Step: 9700/20000, Average Loss: 74.622524
Step: 9800/20000, Average Loss: 65.929333
Step: 9900/20000, Average Loss: 66.220343
Step: 10000/20000, Average Loss: 63.954406
Saved model checkpoint to trained_models_attention/ppm_attention_step_10000.pth
Step: 10100/20000, Average Loss: 61.500147
Step: 10200/20000, Average Loss: 57.320968
Step: 10300/20000, Average Loss: 55.877240
Step: 10400/20000, Average Loss: 57.348314
Step: 10500/20000, Average Loss: 56.893121
Step: 10600/20000, Average Loss: 57.613229
Step: 10700/20000, Average Loss: 58.629628
Step: 10800/20000, Average Loss: 58.803921
Step: 10900/20000, Average Loss: 51.932009
Step: 11000/20000, Average Loss: 55.056131
Saved model checkpoint to trained_models_attention/ppm_attention_step_11000.pth
Step: 11100/20000, Average Loss: 62.538114
Step: 11200/20000, Average Loss: 58.026164
Step: 11300/20000, Average Loss: 57.191064
Step: 11400/20000, Average Loss: 52.096381
Step: 11500/20000, Average Loss: 58.738536
Step: 11600/20000, Average Loss: 54.246349
Step: 11700/20000, Average Loss: 52.440333
Step: 11800/20000, Average Loss: 52.439776
Step: 11900/20000, Average Loss: 50.983942
Step: 12000/20000, Average Loss: 50.359091
Saved model checkpoint to trained_models_attention/ppm_attention_step_12000.pth
Step: 12100/20000, Average Loss: 53.001352
Step: 12200/20000, Average Loss: 45.581055
Step: 12300/20000, Average Loss: 51.477256
Step: 12400/20000, Average Loss: 49.513355
Step: 12500/20000, Average Loss: 47.308513
Step: 12600/20000, Average Loss: 50.813378
Step: 12700/20000, Average Loss: 55.444405
Step: 12800/20000, Average Loss: 56.486509
Step: 12900/20000, Average Loss: 49.991631
Step: 13000/20000, Average Loss: 50.220008
Saved model checkpoint to trained_models_attention/ppm_attention_step_13000.pth
Step: 13100/20000, Average Loss: 50.124393
Step: 13200/20000, Average Loss: 48.205170
Step: 13300/20000, Average Loss: 49.016819
Step: 13400/20000, Average Loss: 52.283620
Step: 13500/20000, Average Loss: 51.226636
Step: 13600/20000, Average Loss: 53.785223
Step: 13700/20000, Average Loss: 50.961810
Step: 13800/20000, Average Loss: 54.196299
Step: 13900/20000, Average Loss: 51.572873
Step: 14000/20000, Average Loss: 50.022399
Saved model checkpoint to trained_models_attention/ppm_attention_step_14000.pth
Step: 14100/20000, Average Loss: 55.898342
Step: 14200/20000, Average Loss: 54.474029
Step: 14300/20000, Average Loss: 50.918347
Step: 14400/20000, Average Loss: 52.597212
Step: 14500/20000, Average Loss: 52.850371
Step: 14600/20000, Average Loss: 50.345304
Step: 14700/20000, Average Loss: 45.880603
Step: 14800/20000, Average Loss: 48.841221
Step: 14900/20000, Average Loss: 46.993547
Step: 15000/20000, Average Loss: 50.951508
Saved model checkpoint to trained_models_attention/ppm_attention_step_15000.pth
Step: 15100/20000, Average Loss: 44.512253
Step: 15200/20000, Average Loss: 47.224908
Step: 15300/20000, Average Loss: 46.709862
Step: 15400/20000, Average Loss: 46.158075
Step: 15500/20000, Average Loss: 50.104631
Step: 15600/20000, Average Loss: 48.563814
Step: 15700/20000, Average Loss: 50.980958
Step: 15800/20000, Average Loss: 50.929449
Step: 15900/20000, Average Loss: 51.341094
Step: 16000/20000, Average Loss: 52.090842
Saved model checkpoint to trained_models_attention/ppm_attention_step_16000.pth
Step: 16100/20000, Average Loss: 49.433970
Step: 16200/20000, Average Loss: 46.655834
Step: 16300/20000, Average Loss: 47.349181
Step: 16400/20000, Average Loss: 51.895874
Step: 16500/20000, Average Loss: 48.495467
Step: 16600/20000, Average Loss: 49.968576
Step: 16700/20000, Average Loss: 52.090482
Step: 16800/20000, Average Loss: 48.285976
Step: 16900/20000, Average Loss: 49.081860
Step: 17000/20000, Average Loss: 48.472661
Saved model checkpoint to trained_models_attention/ppm_attention_step_17000.pth
Step: 17100/20000, Average Loss: 48.224006
Step: 17200/20000, Average Loss: 49.619339
Step: 17300/20000, Average Loss: 48.027261
Step: 17400/20000, Average Loss: 48.558413
Step: 17500/20000, Average Loss: 47.583307
Step: 17600/20000, Average Loss: 47.533230
Step: 17700/20000, Average Loss: 48.852425
Step: 17800/20000, Average Loss: 47.436398
Step: 17900/20000, Average Loss: 46.173395
Step: 18000/20000, Average Loss: 49.080587
Saved model checkpoint to trained_models_attention/ppm_attention_step_18000.pth
Step: 18100/20000, Average Loss: 49.071716
Step: 18200/20000, Average Loss: 47.380091
Step: 18300/20000, Average Loss: 46.748952
Step: 18400/20000, Average Loss: 47.578716
Step: 18500/20000, Average Loss: 46.208556
Step: 18600/20000, Average Loss: 45.895758
Step: 18700/20000, Average Loss: 44.693464
Step: 18800/20000, Average Loss: 48.165946
Step: 18900/20000, Average Loss: 45.478973
Step: 19000/20000, Average Loss: 47.958687
Saved model checkpoint to trained_models_attention/ppm_attention_step_19000.pth
Step: 19100/20000, Average Loss: 46.874242
Step: 19200/20000, Average Loss: 45.732078
Step: 19300/20000, Average Loss: 44.705241
Step: 19400/20000, Average Loss: 51.132767
Step: 19500/20000, Average Loss: 49.207345
Step: 19600/20000, Average Loss: 48.364089
Step: 19700/20000, Average Loss: 50.585929
Step: 19800/20000, Average Loss: 45.562285
Step: 19900/20000, Average Loss: 46.589505
Step: 20000/20000, Average Loss: 48.009629
Saved model checkpoint to trained_models_attention/ppm_attention_step_20000.pth
Step: 100, Loss: 0.589351, LR: 1.00e-05, Time: 1.995s
Step: 200, Loss: 0.155001, LR: 2.00e-05, Time: 2.109s
